{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HistoMIL Multiple Instance Learning Notebook\n",
    "\n",
    "This Jupyter notebook demonstrates how to train a model using multiple instance learning (MIL) on histopathology whole-slide images using HistoMIL. The notebook is divided into three main sections: parameter definition, data preparation, and model definition and training.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Before proceeding with this notebook, please make sure that you have followed the setup instructions provided in the project's README file. This includes creating a conda environment and installing the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5g/t9d5_kvd3kb4yljp4f0pvqqc0000gn/T/ipykernel_4212/2197810549.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#--------------------------> base env setting\n",
    "# avoid pandas warning\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# avoid multiprocessing problem\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "#--------------------------> logging setup\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='|%(asctime)s.%(msecs)03d| [%(levelname)s] %(message)s',\n",
    "    datefmt='%Y-%m-%d|%H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change path to use HistoMIL since it's not a library that is pip installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('/Users/awxlong/Desktop/my-studies/hpc_exps/') # path to parent dir of HistoMIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/awxlong/anaconda3/envs/biomedai/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from HistoMIL.MODEL.Image.MIL.TransMIL.paras import TransMILParas\n",
    "from HistoMIL.MODEL.Image.MIL.DSMIL.paras import DSMILParas\n",
    "from HistoMIL.EXP.paras.env import EnvParas\n",
    "\n",
    "import pickle\n",
    "import wandb\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "The second section of the notebook covers model definition for MIL. This includes defining the MIL model architecture using the parameters defined in the first section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------> model setting\n",
    "\n",
    "# for transmil\n",
    "model_para_transmil = TransMILParas()\n",
    "model_para_transmil.feature_size=512\n",
    "model_para_transmil.n_classes=2\n",
    "model_para_transmil.norm_layer=nn.LayerNorm\n",
    "# for dsmil\n",
    "model_para_dsmil = DSMILParas()\n",
    "model_para_dsmil.feature_dim = 224 # feature embedding size of feature extractor, in this case prov-gigapath's\n",
    "model_para_dsmil.p_class = 2\n",
    "model_para_dsmil.b_class = 2\n",
    "model_para_dsmil.dropout_r = 0.5\n",
    "\n",
    "model_name = \"TransMIL\"  # or \"TransMIL\" or \"ABMIL\"\n",
    "\n",
    "model_para_settings = {\"TransMIL\":model_para_transmil,\n",
    "                       \"DSMIL\":model_para_dsmil} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pre-calculated'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_para_transmil.encoder_name # if you already ran preprocessing and stored the feature vectors, ENSURE this is set as 'pre-calculated'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Definition\n",
    "\n",
    "The first section of the notebook defines the parameters used in the MIL training process. This includes the model architecture, loss function, optimizer, and learning rate scheduler. You can modify these parameters to customize the training process for your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene2k_env = EnvParas()\n",
    "precomputed = True\n",
    "\n",
    "#--------------------------> task setting\n",
    "task_name = \"g0_arrest\" # Coincides with column name of target label\n",
    "\n",
    "#--------------------------> parameters\n",
    "# logging information\n",
    "gene2k_env.exp_name = f\"{model_name}_{task_name}\"\n",
    "gene2k_env.project = \"g0_arrest\" \n",
    "gene2k_env.entity = \"cell-x\"    # make sure it's initialized to an existing wandb entity\n",
    "\n",
    "#----------------> cohort\n",
    "gene2k_env.cohort_para.localcohort_name = \"CRC\" # name of patient cohort \n",
    "gene2k_env.cohort_para.task_name = task_name\n",
    "gene2k_env.cohort_para.cohort_file = f'local_cohort_{gene2k_env.cohort_para.localcohort_name}.csv' # e.g. local_cohort_CRC.csv, this is created automatically, and contains folder, filename, slide_nb, tissue_nb, etc. \n",
    "gene2k_env.cohort_para.task_file = f'{gene2k_env.cohort_para.localcohort_name}_{gene2k_env.cohort_para.task_name}.csv' # e.g. CRC_g0_arrest.csv, which has PatientID matched with g0_arrest labels. This is SUPPLIED by the user and assumed to be stored in the EXP/Data/ directory\n",
    "gene2k_env.cohort_para.pid_name = \"PatientID\"\n",
    "gene2k_env.cohort_para.targets = ['g0_arrest']  # e.g. \"g0_arrest\"  # the column name of interest; supply as a list\n",
    "gene2k_env.cohort_para.targets_idx = 0\n",
    "gene2k_env.cohort_para.label_dict = {'negative':0,'positive':1}  # SINGLE quotations for the keys, converts strings objects to binary values\n",
    "#debug_env.cohort_para.update_localcohort = True\n",
    "#----------------> pre-processing\n",
    "#----------------> dataset\n",
    "gene2k_env.dataset_para.dataset_name = f\"CRC_{task_name}\"\n",
    "gene2k_env.dataset_para.concepts = [\"slide\",\"patch\",\"feature\"] # default ['slide', 'tissue', 'patch', 'feature'] in this ORDER\n",
    "gene2k_env.dataset_para.split_ratio = [0.8,0.2]                # dataset split ratio which must sum to one, and training ratio is greater than testing\n",
    "#----------------> model\n",
    "gene2k_env.trainer_para.model_name = model_name\n",
    "gene2k_env.trainer_para.model_para = model_para_settings[model_name]\n",
    "#----------------> trainer or analyzer\n",
    "if precomputed:\n",
    "    gene2k_env.trainer_para.use_pre_calculated = True ### FOR LOADING COMPUTED FEATURES\n",
    "else:\n",
    "    gene2k_env.trainer_para.backbone_name = \"resnet18\"\n",
    "    gene2k_env.trainer_para.additional_pl_paras.update({\"accumulate_grad_batches\":8})\n",
    "    gene2k_env.trainer_para.label_format = \"int\"#\"one_hot\" \n",
    "\n",
    "\n",
    "#k_fold = None\n",
    "#--------------------------> init machine and person\n",
    "\n",
    "gene2k_env.trainer_para.backbone_name = \"prov-gigapath\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_cohort_loc = \"/Users/awxlong/Desktop/my-studies/hpc_exps/User/CRC_machine_config.pkl\"\n",
    "with open(machine_cohort_loc, \"rb\") as f:   # Unpickling\n",
    "    [data_locs,exp_locs,machine,user] = pickle.load(f)\n",
    "gene2k_env.data_locs = data_locs\n",
    "gene2k_env.exp_locs = exp_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize wandb (once is enough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # api_dir = 'path/to API.env/'                    # We assume you store your API keys in a .env file\n",
    "# # load_dotenv(dotenv_path=f\"{api_dir}API.env\")\n",
    "# # user.wandb_api_key = os.getenv(\"WANDB_API_KEY\") # We assume your wandb API key is named as WANDB_API_KEY in the API.env file                             # should have the api key if machine_config.ipynb was run without problems\n",
    "# user.wandb_api_key                                # should have the API key if the machine_config.ipynb notebook was run without issues\n",
    "\n",
    "# wandb.setup(settings=wandb.Settings(\n",
    "#     _disable_stats=True,\n",
    "#     disable_git=True,\n",
    "#     api_key=user.wandb_api_key  \n",
    "# ))\n",
    "\n",
    "# wandb.init(project=gene2k_env.project, \n",
    "#            entity=gene2k_env.entity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialisation and Training\n",
    "\n",
    "The third and final section of the notebook covers model definition and training. This includes defining the MIL model using the parameters defined in the first section, and training the model using the dataloaders created in the second section.\n",
    "\n",
    "After training is complete, the notebook will also demonstrate how to evaluate the trained model on a validation set and make predictions on new whole-slide images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|2024-06-21|16:42:34.465| [INFO] setup experiment\n",
      "|2024-06-21|16:42:34.466| [INFO] Exp:: Start Environment TransMIL_g0_arrest\n",
      "|2024-06-21|16:42:34.466| [INFO] Exp:: Set up machine\n",
      "|2024-06-21|16:42:34.466| [INFO] setup data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|2024-06-21|16:42:34.467| [INFO] Exp:: Initialise slide-based data cohort\n",
      "|2024-06-21|16:42:34.467| [INFO] Cohort::Set up local cohort for slides at /Users/awxlong/Desktop/my-studies/temp_data/CRC/TCGA-CRC/\n",
      "|2024-06-21|16:42:34.469| [INFO] Cohort::Set up task cohort for file local_cohort_CRC.csv\n",
      "|2024-06-21|16:42:34.470| [INFO] Cohort::Build task cohort use local_cohort_CRC.csv\n",
      "|2024-06-21|16:42:34.474| [INFO] Cohort::Done and task cohort saved as /Users/awxlong/Desktop/my-studies/hpc_exps/Data/Task_g0_arrest.csv\n",
      "|2024-06-21|16:42:34.474| [INFO] setup trainer..\n",
      "|2024-06-21|16:42:34.475| [INFO]  Cohort::Show Task stat with {'negative': 0, 'positive': 1}:\n",
      "|2024-06-21|16:42:34.475| [INFO]  Cohort::Category: positive include 2 slides,\n",
      "|2024-06-21|16:42:34.475| [INFO]                include 31036  patch, \n",
      "|2024-06-21|16:42:34.475| [INFO]  Cohort::Category: negative include 2 slides,\n",
      "|2024-06-21|16:42:34.476| [INFO]                include 32986  patch, \n",
      "|2024-06-21|16:42:34.476| [INFO] Cohort::Shuffle in dataframe level or Cohort level.\n",
      "|2024-06-21|16:42:34.476| [WARNING] Cohort::Using k-fold split rather than ratio.\n",
      "|2024-06-21|16:42:34.477| [INFO] Exp:: Splited train and test data\n",
      "|2024-06-21|16:42:34.956| [INFO] Created a temporary directory at /var/folders/5g/t9d5_kvd3kb4yljp4f0pvqqc0000gn/T/tmp_vt8_kog\n",
      "|2024-06-21|16:42:34.957| [INFO] Writing /var/folders/5g/t9d5_kvd3kb4yljp4f0pvqqc0000gn/T/tmp_vt8_kog/_remote_module_non_scriptable.py\n",
      "|2024-06-21|16:42:35.020| [INFO] Dataset::Using pre-calculated feature for MIL.\n",
      "|2024-06-21|16:42:35.020| [INFO] Dataset::Using resnet18 feature for MIL.\n",
      "|2024-06-21|16:42:35.021| [INFO] Cohort:: For weight sampler, the label distribution is (array([0, 1]), array([2, 1]))\n",
      "|2024-06-21|16:42:35.021| [INFO] Dataset:: Current dataset with class count[2 1] will be sampled as weight [0.33333333 0.66666667]\n",
      "|2024-06-21|16:42:35.022| [INFO] Cohort::Dataloader paras as {'batch_size': 1, 'sampler': <torch.utils.data.sampler.WeightedRandomSampler object at 0x364648070>}\n",
      "|2024-06-21|16:42:35.025| [INFO] Dataset::Using pre-calculated feature for MIL.\n",
      "|2024-06-21|16:42:35.026| [INFO] Dataset::Using resnet18 feature for MIL.\n",
      "|2024-06-21|16:42:35.026| [INFO] Cohort::Dataloader paras as {'batch_size': 1, 'shuffle': False}\n",
      "|2024-06-21|16:42:35.028| [INFO] Trainer:: Build model: TransMIL:(mil) with backbone:resnet18\n",
      "|2024-06-21|16:42:35.039| [INFO] Trainer:: Use pre-calculated feature: pre-calculated\n",
      "|2024-06-21|16:42:35.040| [INFO] Trainer:: Create image model with paras: TransMILParas(encoder_pretrained=True, feature_size=512, embed_size=None, n_classes=2)\n",
      "|2024-06-21|16:42:35.040| [INFO] init TransMIL with paras: TransMILParas(encoder_pretrained=True, feature_size=512, embed_size=None, n_classes=2)\n",
      "|2024-06-21|16:42:35.041| [INFO] FeatureNet:: Use: pre-calculated \n",
      "|2024-06-21|16:42:35.045| [INFO] Create loss function ['CrossEntropyLoss']\n",
      "|2024-06-21|16:42:35.048| [INFO] TransMIL pl protocol init done.\n",
      "|2024-06-21|16:42:35.100| [ERROR] Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manwangxuelong\u001b[0m (\u001b[33mcell-x\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240621_164235-55y0vjxp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cell-x/g0_arrest/runs/55y0vjxp' target=\"_blank\">TransMIL_g0_arrest</a></strong> to <a href='https://wandb.ai/cell-x/g0_arrest' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cell-x/g0_arrest' target=\"_blank\">https://wandb.ai/cell-x/g0_arrest</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cell-x/g0_arrest/runs/55y0vjxp' target=\"_blank\">https://wandb.ai/cell-x/g0_arrest/runs/55y0vjxp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|2024-06-21|16:42:38.833| [INFO] Trainer:: Best model will be saved at /Users/awxlong/Desktop/my-studies/hpc_exps/SavedModels/ as TransMIL_g0_arrest_{epoch:02d}-{auroc:.2f}\n",
      "|2024-06-21|16:42:38.877| [INFO] GPU available: True (mps), used: True\n",
      "|2024-06-21|16:42:38.878| [INFO] TPU available: False, using: 0 TPU cores\n",
      "|2024-06-21|16:42:38.879| [INFO] IPU available: False, using: 0 IPUs\n",
      "|2024-06-21|16:42:38.880| [INFO] HPU available: False, using: 0 HPUs\n",
      "|2024-06-21|16:42:38.882| [INFO] Trainer:: Start training....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/awxlong/Desktop/my-studies/hpc_exps/HistoMIL/EXP/trainer/base.py\u001b[0m(97)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     95 \u001b[0;31m        \u001b[0mvalloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_pack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"testloader\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     96 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 97 \u001b[0;31m        self.trainer.fit(model=self.pl_model, \n",
      "\u001b[0m\u001b[0;32m     98 \u001b[0;31m                \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     99 \u001b[0;31m                val_dataloaders=valloader)\n",
      "\u001b[0m\n",
      "[tensor([[[1.4635e-02, 0.0000e+00, 1.3146e-01,  ..., 2.2182e-01,\n",
      "          3.0558e-02, 6.4946e-01],\n",
      "         [1.6679e-01, 4.2147e-03, 1.2958e-02,  ..., 5.9249e-01,\n",
      "          5.1140e-04, 5.9399e-01],\n",
      "         [3.8960e-01, 0.0000e+00, 3.0880e-02,  ..., 7.9045e-01,\n",
      "          2.6434e-02, 1.0822e+00],\n",
      "         ...,\n",
      "         [1.6688e-01, 0.0000e+00, 1.8930e-01,  ..., 3.8207e-01,\n",
      "          5.5153e-03, 1.7737e-01],\n",
      "         [5.9639e-02, 0.0000e+00, 2.8148e-01,  ..., 5.9383e-02,\n",
      "          4.7247e-02, 2.3928e-01],\n",
      "         [1.6516e-01, 3.7006e-03, 2.0140e-01,  ..., 1.3395e-01,\n",
      "          6.1720e-03, 3.3960e-01]]]), tensor([0])]\n",
      "2\n",
      "tensor([[[1.4635e-02, 0.0000e+00, 1.3146e-01,  ..., 2.2182e-01,\n",
      "          3.0558e-02, 6.4946e-01],\n",
      "         [1.6679e-01, 4.2147e-03, 1.2958e-02,  ..., 5.9249e-01,\n",
      "          5.1140e-04, 5.9399e-01],\n",
      "         [3.8960e-01, 0.0000e+00, 3.0880e-02,  ..., 7.9045e-01,\n",
      "          2.6434e-02, 1.0822e+00],\n",
      "         ...,\n",
      "         [1.6688e-01, 0.0000e+00, 1.8930e-01,  ..., 3.8207e-01,\n",
      "          5.5153e-03, 1.7737e-01],\n",
      "         [5.9639e-02, 0.0000e+00, 2.8148e-01,  ..., 5.9383e-02,\n",
      "          4.7247e-02, 2.3928e-01],\n",
      "         [1.6516e-01, 3.7006e-03, 2.0140e-01,  ..., 1.3395e-01,\n",
      "          6.1720e-03, 3.3960e-01]]])\n",
      "torch.Size([1, 16493, 512])\n",
      "torch.Size([1, 16493, 512])\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"setup experiment\")\n",
    "from HistoMIL.EXP.workspace.experiment import Experiment\n",
    "exp = Experiment(env_paras=gene2k_env)\n",
    "exp.setup_machine(machine=machine,user=user)\n",
    "logging.info(\"setup data\")\n",
    "exp.init_cohort()\n",
    "logging.info(\"setup trainer..\")\n",
    "exp.setup_experiment(main_data_source=\"slide\",\n",
    "                    need_train=True)\n",
    "\n",
    "exp.exp_worker.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Histo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
