{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HistoMIL Self-Supervised Learning Notebook\n",
    "\n",
    "This Jupyter notebook demonstrates how to train a model using self-supervised learning on histopathology whole-slide images using HistoMIL. The notebook is divided into three main sections: parameter definition, data preparation, and model definition and training.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Before proceeding with this notebook, please make sure that you have followed the setup instructions provided in the project's README file. This includes creating a conda environment and installing the required dependencies.\n",
    "\n",
    "## Parameter Definition\n",
    "\n",
    "The first section of the notebook defines the parameters used in the self-supervised learning training process. This includes the model architecture, loss function, optimizer, and learning rate scheduler. You can modify these parameters to customize the training process for your specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid pandas warning\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# avoid multiprocessing problem\n",
    "import torch\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "from HistoMIL import logger\n",
    "import logging\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "#------>stop skimage warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import imageio.core.util\n",
    "import skimage \n",
    "def ignore_warnings(*args, **kwargs):\n",
    "    pass\n",
    "imageio.core.util._precision_warn = ignore_warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------> parameters\n",
    "from HistoMIL.EXP.paras.env import EnvParas\n",
    "ssl_env = EnvParas()\n",
    "ssl_env.exp_name = \"debug_SSL_MoCo\"\n",
    "ssl_env.project = \"test-project\" \n",
    "ssl_env.entity = \"shipan_work\"\n",
    "#----------------> cohort\n",
    "ssl_env.cohort_para.localcohort_name = \"BRCA\"\n",
    "ssl_env.cohort_para.task_name = \"DNAD\"\n",
    "ssl_env.cohort_para.cohort_file = \"/DNAD/DNAD_L2.csv\"\n",
    "ssl_env.cohort_para.pid_name = \"PatientID\"\n",
    "ssl_env.cohort_para.targets = [\"HRD\"]\n",
    "ssl_env.cohort_para.targets_idx = 0\n",
    "ssl_env.cohort_para.label_dict = {\"HRD\":0,\"HRP\":1}\n",
    "#ssl_env.cohort_para.update_localcohort = True\n",
    "#----------------> pre-processing\n",
    "\n",
    "#----------------> model\n",
    "ssl_env.trainer_para.method_type = \"patch_learning\"\n",
    "ssl_env.trainer_para.model_name = \"moco\" # \n",
    "from HistoMIL.MODEL.Image.SSL.paras import SSLParas\n",
    "ssl_env.trainer_para.model_para = SSLParas()\n",
    "#----------------> dataset\n",
    "ssl_env.dataset_para.dataset_name = \"DNAD_L2\"\n",
    "ssl_env.dataset_para.concepts = [\"slide\",\"patch\"]\n",
    "ssl_env.dataset_para.split_ratio = [0.99,0.01]\n",
    "#################----> for ssl\n",
    "ssl_env.trainer_para.model_para.ssl_dataset_para.batch_size = 16\n",
    "ssl_env.trainer_para.model_para.ssl_dataset_para.label_dict = {\"HRD\":0,\"HRP\":1}\n",
    "ssl_env.trainer_para.model_para.ssl_dataset_para.example_file = \"example/example.png\"\n",
    "ssl_env.trainer_para.model_para.ssl_dataset_para.is_weight_sampler = True\n",
    "ssl_env.trainer_para.model_para.ssl_dataset_para.force_balance_val = True\n",
    "ssl_env.trainer_para.model_para.ssl_dataset_para.add_dataloader = {\n",
    "                                                    \"pin_memory\":True,\n",
    "                                                    \"drop_last\":True,\n",
    "                                                    }\n",
    "\n",
    "from HistoMIL.DATA.Database.data_aug import SSL_DataAug\n",
    "# specifu data aug or use default can be found at paras\n",
    "ssl_env.trainer_para.model_para.ssl_dataset_para.img_size = (512,512)\n",
    "add_data_aug_paras = ssl_env.trainer_para.model_para.ssl_dataset_para.add_data_aug_paras\n",
    "trans_factory = SSL_DataAug(**add_data_aug_paras)\n",
    "ssl_env.trainer_para.model_para.ssl_dataset_para.transfer_fn = trans_factory.get_trans_fn\n",
    "#----------------> trainer or analyzer\n",
    "ssl_env.trainer_para.label_format = \"int\"#\"one_hot\" \n",
    "ssl_env.trainer_para.additional_pl_paras={\n",
    "                #---------> paras for pytorch lightning trainner\n",
    "                \"accumulate_grad_batches\":16, # mil need accumulated grad\n",
    "                \"accelerator\":\"auto\",#accelerator='gpu', devices=1,\n",
    "            }\n",
    "#ssl_env.trainer_para.with_logger = None #without wandb to debug\n",
    "#--------------------------> init machine and person\n",
    "#--------------------------> init machine and person\n",
    "import pickle\n",
    "machine_cohort_loc = \"Path/to/BRCA_machine_config.pkl\"\n",
    "with open(machine_cohort_loc, \"rb\") as f:   # Unpickling\n",
    "    [data_locs,exp_locs,machine,user] = pickle.load(f)\n",
    "ssl_env.data_locs = data_locs\n",
    "ssl_env.exp_locs = exp_locs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logger.info(\"setup experiment\")\n",
    "from HistoMIL.EXP.workspace.experiment import Experiment\n",
    "exp = Experiment(env_paras=ssl_env)\n",
    "exp.setup_machine(machine=machine,user=user)\n",
    "logger.info(\"setup data\")\n",
    "exp.init_cohort()\n",
    "logger.info(\"setup dataset and dataloader..\")\n",
    "exp.data_cohort.split_train_phase()\n",
    "\n",
    "logger.info(\"setup trainer..\")\n",
    "from HistoMIL.EXP.trainer.ssl import pl_ssl_trainer\n",
    "worker = pl_ssl_trainer(trainer_para=ssl_env.trainer_para,\n",
    "                        dataset_para=ssl_env.trainer_para.model_para.ssl_dataset_para,\n",
    "                        opt_para=ssl_env.trainer_para.model_para.ssl_opt_loss_para)\n",
    "worker.get_env_info(machine=machine,user=user,project=ssl_env.project,\n",
    "                    entity=ssl_env.entity,exp_name=ssl_env.exp_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The second section of the notebook covers data preparation for self-supervised learning training. This includes creating a MIL dataset from the preprocessed patches and features, and creating dataloaders for training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker.set_cohort(exp.data_cohort)\n",
    "worker.get_datapack(machine=machine,collector_para=ssl_env.collector_para)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition and Training\n",
    "\n",
    "The third and final section of the notebook covers model definition and training. This includes defining the self-supervised learning model using the parameters defined in the first section, and training the model using the dataloaders created in the second section.\n",
    "\n",
    "After training is complete, the notebook will also demonstrate how to evaluate the trained model on a validation set and make predictions on new whole-slide images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker.build_trainer()\n",
    "worker.build_model()\n",
    "\n",
    "worker.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Histo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
