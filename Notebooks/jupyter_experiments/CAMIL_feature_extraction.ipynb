{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/Users/awxlong/Desktop/my-studies/hpc_exps/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/awxlong/anaconda3/envs/biomedai/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from HistoMIL.MODEL.Image.MIL.CAMIL.model import CAMIL\n",
    "from HistoMIL.MODEL.Image.MIL.CAMIL.paras import CAMILParas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import torch\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from HistoMIL import logger\n",
    "import logging\n",
    "logger.setLevel(logging.INFO)\n",
    "import pdb\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_coords = np.random.rand(50000, 2)  # Example coordinates, adjust as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances_in_batches(X, batch_size=1000, dtype=np.float32):\n",
    "    n = X.shape[0]\n",
    "    for i in range(0, n, batch_size):\n",
    "        end = min(i + batch_size, n)\n",
    "        batch_distances = pairwise_distances(X[i:end], X, metric='euclidean')\n",
    "        yield batch_distances\n",
    "\n",
    "# Usage\n",
    "n_neighbors = 16\n",
    "neighbor_indices1 = np.empty((wsi_coords.shape[0], n_neighbors), dtype=np.int32)\n",
    "\n",
    "for idx, batch_patch_distance in enumerate(compute_distances_in_batches(wsi_coords)):\n",
    "    start_idx = idx * 1000\n",
    "    end_idx = min((idx + 1) * 1000, wsi_coords.shape[0])\n",
    "    \n",
    "    for i, distances in enumerate(batch_patch_distance):\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        neighbor_indices1[start_idx + i] = sorted_indices[:n_neighbors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,  7143, 10266, ..., 36077, 15807, 44363],\n",
       "       [    1,  7522,    59, ..., 11008,   730, 45156],\n",
       "       [    2, 27715,  6842, ..., 18511, 38590, 18908],\n",
       "       ...,\n",
       "       [49997, 42113,  1880, ..., 43379, 16423,  2458],\n",
       "       [49998, 36904, 32821, ..., 44512, 26961,  8203],\n",
       "       [49999, 28933,  8963, ..., 26826, 33334, 31734]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbor_indices1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_distances = pairwise_distances(wsi_coords, metric='euclidean', n_jobs=1)\n",
    "neighbor_indices2 = np.argsort(patch_distances, axis=1)[:, :16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,  7143, 10266, ..., 36077, 15807, 44363],\n",
       "       [    1,  7522,    59, ..., 11008,   730, 45156],\n",
       "       [    2, 27715,  6842, ..., 18511, 38590, 18908],\n",
       "       ...,\n",
       "       [49997, 42113,  1880, ..., 43379, 16423,  2458],\n",
       "       [49998, 36904, 32821, ..., 44512, 26961,  8203],\n",
       "       [49999, 28933,  8963, ..., 26826, 33334, 31734]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbor_indices2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m neighbor_indices1 \u001b[38;5;241m==\u001b[39m neighbor_indices2\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "assert neighbor_indices1 == neighbor_indices2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wsi_coords = h5py.File('/Users/awxlong/Desktop/my-studies/temp_data/CRC/Patch/224_224/tcga_folder_4.TCGA-A8-A086-01Z-00-DX1.2B52D1B8-5AD4-4BD6-ADF7-9D65B8EE2623.svs.h5', 'r')\n",
    "# wsi_coords = wsi_coords['coords']\n",
    "# wsi_coords2 = h5py.File('/Users/awxlong/Desktop/my-studies/temp_data/CRC/Patch/224_224/tcga_folder_4.TCGA-AA-A01X-01Z-00-DX1.7433F54C-2A79-467A-8FEA-638AE48F42A0.svs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wsi_feats = torch.load('/Users/awxlong/Desktop/my-studies/temp_data/CRC/Feature/resnet18/tcga_folder_3.TCGA-A8-A086-01Z-00-DX1.2B52D1B8-5AD4-4BD6-ADF7-9D65B8EE2623.svs.pt')\n",
    "# wsi_feats2 = torch.load('/Users/awxlong/Desktop/my-studies/temp_data/CRC/Feature/resnet18/tcga_folder_4.TCGA-AA-A01X-01Z-00-DX1.7433F54C-2A79-467A-8FEA-638AE48F42A0.svs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = []\n",
    "# features.append(wsi_feats.cpu().numpy())\n",
    "# features.append(wsi_feats2.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.vstack(features).shape\n",
    "# wsi_coords.shape\n",
    "# wsi_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------> init machine and person\n",
    "\n",
    "machine_cohort_loc = '/Users/awxlong/Desktop/my-studies/hpc_exps/User/CRC_machine_config.pkl'#  f\"{args.cohort_dir}/User/{args.localcohort_name}_machine_config.pkl\"\n",
    "with open(machine_cohort_loc, \"rb\") as f:   # Unpickling\n",
    "    [data_locs,exp_locs,machine,user] = pickle.load(f)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hdf5(output_path, asset_dict, attr_dict=None, mode='a'):\n",
    "    file = h5py.File(output_path, mode)\n",
    "    for key, val in asset_dict.items():\n",
    "        data_shape = val.shape\n",
    "        if key not in file:\n",
    "            data_type = val.dtype\n",
    "            chunk_shape = (1,) + data_shape[1:]\n",
    "            maxshape = (None,) + data_shape[1:]\n",
    "            dset = file.create_dataset(key, shape=data_shape, maxshape=maxshape, chunks=chunk_shape, dtype=data_type)\n",
    "            dset[:] = val\n",
    "            if attr_dict is not None:\n",
    "                if key in attr_dict.keys():\n",
    "                    for attr_key, attr_val in attr_dict[key].items():\n",
    "                        dset.attrs[attr_key] = attr_val\n",
    "        else:\n",
    "            dset = file[key]\n",
    "            dset.resize(len(dset) + data_shape[0], axis=0)\n",
    "            dset[-data_shape[0]:] = val\n",
    "    file.close()\n",
    "    return output_path\n",
    "\n",
    "def compute_adj_coords(wsi_coords, wsi_feats, wsi_name, adj_coord_save_path, adj_matrix_save_path, force_recalc = False):\n",
    "        # output_path_file = os.path.join(save_path + wsi_name + '.h5')\n",
    "        # output_path_file = data_locs.abs_loc('feature') + f'{encoder}_adj_dictionary/{wsi_name}.h5'\n",
    "        if not os.path.exists(f'{adj_matrix_save_path}{wsi_name}.pt') or force_recalc: \n",
    "             \n",
    "            patch_distances = pairwise_distances(wsi_coords, metric='euclidean', n_jobs=1)\n",
    "            neighbor_indices = np.argsort(patch_distances, axis=1)[:, :16]\n",
    "            rows = np.asarray([[enum] * len(item) for enum, item in enumerate(neighbor_indices)]).ravel()\n",
    "            columns = neighbor_indices.ravel()\n",
    "            values = []\n",
    "            coords = []\n",
    "            for row, column in zip(rows, columns):\n",
    "                    m1 = np.expand_dims(wsi_feats[int(row)], axis=0)\n",
    "                    # pdb.set_trace()\n",
    "                    m2 = np.expand_dims(wsi_feats[int(column)], axis=0)\n",
    "                    value = distance.cdist(m1.reshape(1, -1), m2.reshape(1, -1), 'cosine')[0][0]\n",
    "                    values.append(value)\n",
    "                    coords.append((row, column))\n",
    "            \n",
    "            # mode = 'a'\n",
    "            values = np.reshape(values, (wsi_coords.shape[0], neighbor_indices.shape[1]))\n",
    "            \n",
    "            coords = np.array(coords)\n",
    "            \n",
    "            asset_dict = {'adj_coords': coords, 'similarities': values, 'indices': neighbor_indices}\n",
    "\n",
    "            save_hdf5(adj_coord_save_path, asset_dict, attr_dict=None)\n",
    "\n",
    "            ### compute adjacency matrix\n",
    "            values = np.nan_to_num(values)\n",
    "\n",
    "            Idx = neighbor_indices[:, :8]\n",
    "            rows = np.asarray([[enum] * len(item) for enum, item in enumerate(Idx)]).ravel()\n",
    "\n",
    "            columns = Idx.ravel()\n",
    "\n",
    "            neighbor_matrix = values[:, 1:]\n",
    "\n",
    "            normalized_matrix = preprocessing.normalize(neighbor_matrix, norm=\"l2\")\n",
    "\n",
    "            similarities = np.exp(-normalized_matrix)\n",
    "\n",
    "            values = np.concatenate((np.max(similarities, axis=1).reshape(-1, 1), similarities), axis=1)\n",
    "\n",
    "            values = values[:, :8]\n",
    "\n",
    "            values = values.ravel().tolist()\n",
    "\n",
    "            sparse_coords= list(zip(rows, columns))\n",
    "\n",
    "            # sparse_matrix = torch.sparse_coo_tensor(sparse_coords, values, (wsi_feats2.shape[0], wsi_feats2.shape[0]))\n",
    "\n",
    "            indices = torch.tensor(sparse_coords, dtype=torch.long).t()\n",
    "            # values = torch.tensor(values, dtype=torch.float32)\n",
    "            values = torch.FloatTensor(values)\n",
    "            sparse_matrix = torch.sparse.FloatTensor(indices, values, torch.Size([wsi_feats.shape[0], wsi_feats.shape[0]]))\n",
    "\n",
    "            torch.save(sparse_matrix, f'{adj_matrix_save_path}{wsi_name}.pt')\n",
    "            logger.info(f'Adjacency matrix stored at {adj_matrix_save_path}')\n",
    "        else:\n",
    "             logger.info(f'Adjacency matrix already exists at: {adj_matrix_save_path}{wsi_name}.pt')\n",
    "        # return np.array(coords), values, neighbor_indices, sparse_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_name = 'CRC'\n",
    "idx = 1\n",
    "local_cohort_dir = f'{exp_locs.root}Data/local_cohort_{cohort_name}_{idx}.csv'\n",
    "df = pd.read_csv(local_cohort_dir)\n",
    "\n",
    "step_size = 224\n",
    "encoder = 'resnet18'\n",
    "\n",
    "wsi_coord_root = data_locs.abs_loc('patch') + f'{step_size}_{step_size}/'\n",
    "wsi_feats_root = data_locs.abs_loc('feature') + f'{encoder}/'\n",
    "\n",
    "h5_path_root = data_locs.abs_loc('feature') + f'{encoder}_adj_dictionary/'\n",
    "sparse_matrix_root = data_locs.abs_loc('feature') + f'{encoder}_adj_matrix/'\n",
    "\n",
    "os.makedirs(h5_path_root, exist_ok=True)\n",
    "os.makedirs(sparse_matrix_root, exist_ok=True)\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    wsi_name = f'{df.loc[i, \"folder\"]}.{df.loc[i, \"filename\"]}'\n",
    "    wsi_coords_name = f'{wsi_name}.h5'\n",
    "    wsi_feats = f'{wsi_name}.pt'\n",
    "\n",
    "    wsi_coords_dir = f'{wsi_coord_root}{wsi_coords_name}'\n",
    "    wsi_feats_dir = f'{wsi_feats_root}{wsi_feats}'\n",
    "    if os.path.exists(wsi_coords_dir) and os.path.exists(wsi_feats_dir):\n",
    "            # Load the slide and its coordinates\n",
    "            wsi_coordinates = h5py.File(wsi_coords_dir)\n",
    "            wsi_coordinates = wsi_coordinates['coords']\n",
    "            wsi_features = torch.load(wsi_feats_dir)  \n",
    "            \n",
    "            adj_coords_save_path = f'{h5_path_root}{wsi_name}.h5' # data_locs.abs_loc('feature') + f'{encoder}_adj_dictionary/{wsi_name}.h5'\n",
    "            adj_matrix_save_path = f'{sparse_matrix_root}{wsi_name}.pt'\n",
    "            \n",
    "            # Process the slide and its coordinates\n",
    "            compute_adj_coords(wsi_coords = wsi_coordinates, \n",
    "                               wsi_feats = wsi_features,\n",
    "                               wsi_name = wsi_name,\n",
    "                               adj_coord_save_path=adj_matrix_save_path,\n",
    "                               adj_matrix_save_path=adj_coords_save_path,\n",
    "                               force_recalc=False\n",
    "                               )\n",
    "            \n",
    "             \n",
    "    else:\n",
    "            # Do nothing and continue to the next iteration\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "adj_coords, similarities, neighbor_indices, sparse_matrix = compute_adj_coords(wsi_coords=wsi_coords2['coords'], wsi_feats=wsi_feats2)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_feat = torch.rand((1, 29015, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[    0,     0,     0,  ..., 29014, 29014, 29014],\n",
       "                       [    0,     1,     8,  ..., 29012, 28997, 29007]]),\n",
       "       values=tensor([0.7506, 0.7501, 0.7484,  ..., 0.7493, 0.7493, 0.7493]),\n",
       "       size=(29015, 29015), nnz=232120, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = torch.load('/Users/awxlong/Desktop/my-studies/temp_data/CRC/Feature/uni_adj_matrix/temp_sparse_matrix.pt')\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_paras = CAMILParas()\n",
    "default_paras.input_shape = 512\n",
    "rand_tensor = torch.rand(1, 1, 512)# .to('mps')\n",
    "model = CAMIL(paras=default_paras)\n",
    "# model.to('mps')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (29184x1024 and 512x1536)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out, alpha, k_alpha \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43muni_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtst\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/biomedai/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/my-studies/hpc_exps/HistoMIL/MODEL/Image/MIL/CAMIL/model.py:352\u001b[0m, in \u001b[0;36mCAMIL.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m    350\u001b[0m     bag, adjacency_matrix \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m--> 352\u001b[0m     xo, alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjacency_matrix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m     k_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattcls(xo)\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# pdb.set_trace()\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/biomedai/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/my-studies/hpc_exps/HistoMIL/MODEL/Image/MIL/CAMIL/model.py:303\u001b[0m, in \u001b[0;36mencoder.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m    301\u001b[0m     dense, sparse_adj \u001b[38;5;241m=\u001b[39m inputs  \u001b[38;5;66;03m# adjacency matrix\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m     encoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnyst_att\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     xg \u001b[38;5;241m=\u001b[39m encoder_output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    307\u001b[0m     encoder_output \u001b[38;5;241m=\u001b[39m xg \u001b[38;5;241m+\u001b[39m dense\n",
      "File \u001b[0;32m~/anaconda3/envs/biomedai/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/my-studies/hpc_exps/HistoMIL/MODEL/Image/MIL/utils.py:577\u001b[0m, in \u001b[0;36mNystromAttention.forward\u001b[0;34m(self, x, mask, return_attn)\u001b[0m\n\u001b[1;32m    573\u001b[0m         mask \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(mask, (padding, \u001b[38;5;241m0\u001b[39m), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    575\u001b[0m \u001b[38;5;66;03m# derive query, keys, values\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_qkv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m3\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    578\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m t: rearrange(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb n (h d) -> b h n d\u001b[39m\u001b[38;5;124m'\u001b[39m, h\u001b[38;5;241m=\u001b[39mh), (q, k, v)\n\u001b[1;32m    580\u001b[0m )\n\u001b[1;32m    582\u001b[0m \u001b[38;5;66;03m# set masked positions to 0 in queries, keys, values\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/biomedai/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/biomedai/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (29184x1024 and 512x1536)"
     ]
    }
   ],
   "source": [
    "out, alpha, k_alpha = model([uni_feat, tst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomedai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
