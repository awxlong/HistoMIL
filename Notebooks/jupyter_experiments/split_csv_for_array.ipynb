{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5g/t9d5_kvd3kb4yljp4f0pvqqc0000gn/T/ipykernel_3185/3795637154.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files /Users/awxlong/Desktop/my-studies/hpc_exps/Data/COAD_g0_arrest_1.csv and /Users/awxlong/Desktop/my-studies/hpc_exps/Data/local_cohort_COAD_1.csv have been split and saved successfully.\n",
      "Files /Users/awxlong/Desktop/my-studies/hpc_exps/Data/COAD_g0_arrest_2.csv and /Users/awxlong/Desktop/my-studies/hpc_exps/Data/local_cohort_COAD_2.csv have been split and saved successfully.\n",
      "Files /Users/awxlong/Desktop/my-studies/hpc_exps/Data/COAD_g0_arrest_3.csv and /Users/awxlong/Desktop/my-studies/hpc_exps/Data/local_cohort_COAD_3.csv have been split and saved successfully.\n",
      "Files /Users/awxlong/Desktop/my-studies/hpc_exps/Data/COAD_g0_arrest_4.csv and /Users/awxlong/Desktop/my-studies/hpc_exps/Data/local_cohort_COAD_4.csv have been split and saved successfully.\n",
      "Files /Users/awxlong/Desktop/my-studies/hpc_exps/Data/COAD_g0_arrest_5.csv and /Users/awxlong/Desktop/my-studies/hpc_exps/Data/local_cohort_COAD_5.csv have been split and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV files\n",
    "\n",
    "idx = 5\n",
    "cohort_name = 'COAD'\n",
    "task_name = 'g0_arrest'\n",
    "root = '/Users/awxlong/Desktop/my-studies/hpc_exps/Data/'\n",
    "df1 = pd.read_csv(f'{root}local_cohort_{cohort_name}.csv')\n",
    "df2 = pd.read_csv(f'{root}{cohort_name}_{task_name}.csv')\n",
    "\n",
    "# Merge the dataframes on PatientID\n",
    "merged_df = pd.merge(df1, df2, on='PatientID').drop_duplicates()\n",
    "\n",
    "# Calculate the number of rows for each part\n",
    "total_rows = len(merged_df)\n",
    "rows_per_part = math.ceil(total_rows / idx)\n",
    "\n",
    "# Split and save the data\n",
    "for i in range(idx):\n",
    "    start_idx = i * rows_per_part\n",
    "    end_idx = min((i + 1) * rows_per_part, total_rows)\n",
    "    \n",
    "    # Split the merged dataframe\n",
    "    part_df = merged_df.iloc[start_idx:end_idx]\n",
    "    \n",
    "    # Split df1\n",
    "    part_df1 = part_df[df1.columns]\n",
    "    part_df1.to_csv(f'{root}local_cohort_{cohort_name}_{i+1}.csv', index=False)\n",
    "    \n",
    "    # Split df2\n",
    "    part_df2 = part_df[['PatientID', f'{task_name}']]\n",
    "    part_df2.to_csv(f'{root}{cohort_name}_{task_name}_{i+1}.csv', index=False)\n",
    "    print(f\"Files {root}{cohort_name}_{task_name}_{i+1}.csv and {root}local_cohort_{cohort_name}_{i+1}.csv have been split and saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx - end_idx\n",
    "159 * 2 + 157\n",
    "total_rows\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strings that are different between the two lists:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# rows_per_part * 5 \n",
    "lst1 = list(df1['PatientID'])\n",
    "lst2 = list(df2['PatientID'])\n",
    "\n",
    "# Convert lists to sets\n",
    "set1 = set(lst1)\n",
    "set2 = set(lst2)\n",
    "\n",
    "# Find the differences\n",
    "diff1 = set1 - set2  # Elements in list1 but not in list2\n",
    "diff2 = set2 - set1  # Elements in list2 but not in list1\n",
    "\n",
    "# Combine the differences\n",
    "differences = diff1.union(diff2)\n",
    "\n",
    "# Convert the set back to a list (if needed)\n",
    "differences_list = list(differences)\n",
    "\n",
    "# Print the results\n",
    "print(\"Strings that are different between the two lists:\")\n",
    "print(differences_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomedai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
