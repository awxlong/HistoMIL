{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(mode='disabled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = 'cell-x'\n",
    "project = 'g0-arrest-uni-cv5'\n",
    "\n",
    "runs1 = wandb.Api().runs(f\"{entity}/{project}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = 'cell-x'\n",
    "project = 'g0-arrest-resnet50-cv5'\n",
    "runs2 =  wandb.Api().runs(f\"{entity}/{project}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_mean_val(runs, index):\n",
    "    \n",
    "    run_f1_scores = {}\n",
    "    run_auroc_val_scores = {}\n",
    "    # Iterate over the runs\n",
    "    for run in runs:\n",
    "        # Retrieve the run history for the current run\n",
    "        history = run.history(pandas=True)\n",
    "        \n",
    "        # Extract the validation F1 scores from the history\n",
    "        val_f1_scores = history['f1_val'].dropna().tolist()\n",
    "        auroc_val_scores = history['auroc_val'].dropna().tolist()\n",
    "        \n",
    "        # Store the validation F1 scores for the current run\n",
    "        run_f1_scores[run.id] = val_f1_scores\n",
    "        run_auroc_val_scores[run.id] = auroc_val_scores\n",
    "\n",
    "    # # Print the validation F1 scores for each run\n",
    "    # for run_id, f1_scores in run_f1_scores.items():\n",
    "    #     print(f\"Run ID: {run_id}\")\n",
    "    #     print(f\"Validation F1 Scores: {f1_scores}\")\n",
    "    #     print()\n",
    "    mean_f1_scores = []\n",
    "    mean_auroc_val_scores = []\n",
    "    \n",
    "    index += 1\n",
    "    for run_id, f1_scores in run_f1_scores.items():\n",
    "        # Get the F1 score for the 7th epoch\n",
    "        f1_ith_epoch = f1_scores[index]  # Assuming 0-based indexing\n",
    "        \n",
    "        # Append the F1 score to the list\n",
    "        mean_f1_scores.append(f1_ith_epoch)\n",
    "        mean_auroc_val_scores.append(run_auroc_val_scores[run_id][index])\n",
    "    # Compute the mean of the F1 scores for the ith epoch\n",
    "    overall_mean_f1 = np.mean(mean_f1_scores)\n",
    "    overall_std_f1 = np.std(mean_f1_scores)\n",
    "\n",
    "\n",
    "    overall_mean_auroc_val = np.mean(mean_auroc_val_scores)\n",
    "    overall_std_auroc_val  = np.std(mean_auroc_val_scores)\n",
    "\n",
    "    print(f\"Mean F1 score for the {index}th epoch across all runs: {overall_mean_f1:.4f}\")\n",
    "    print(f\"Std. F1 score for the {index}th epoch across all runs: {overall_std_f1:.4f}\")\n",
    "\n",
    "    print(f\"Mean AUROC VAL score for the {index}th epoch across all runs: {overall_mean_auroc_val:.4f}\")\n",
    "    print(f\"Std. AUROC VAL score for the {index}th epoch across all runs: {overall_std_auroc_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_metrics(runs, index):\n",
    "    run_f1_scores = {}\n",
    "    run_auroc_val_scores = {}\n",
    "    \n",
    "    for run in runs:\n",
    "        history = run.history(pandas=True)\n",
    "        val_f1_scores = history['f1_val'].dropna().tolist()\n",
    "        auroc_val_scores = history['auroc_val'].dropna().tolist()\n",
    "        \n",
    "        run_f1_scores[run.id] = val_f1_scores\n",
    "        run_auroc_val_scores[run.id] = auroc_val_scores\n",
    "    \n",
    "    mean_f1_scores = [f1_scores[index] for f1_scores in run_f1_scores.values()]\n",
    "    mean_auroc_val_scores = [auroc_val_scores[index] for auroc_val_scores in run_auroc_val_scores.values()]\n",
    "    \n",
    "    overall_mean_f1 = np.mean(mean_f1_scores)\n",
    "    overall_std_f1 = np.std(mean_f1_scores)\n",
    "    \n",
    "    overall_mean_auroc_val = np.mean(mean_auroc_val_scores)\n",
    "    overall_std_auroc_val = np.std(mean_auroc_val_scores)\n",
    "    \n",
    "    print(f\"Mean F1 score for the {index}th epoch across all runs: {overall_mean_f1:.4f}\")\n",
    "    print(f\"Std. F1 score for the {index}th epoch across all runs: {overall_std_f1:.4f}\")\n",
    "    \n",
    "    print(f\"Mean AUROC VAL score for the {index}th epoch across all runs: {overall_mean_auroc_val:.4f}\")\n",
    "    print(f\"Std. AUROC VAL score for the {index}th epoch across all runs: {overall_std_auroc_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 score for the 8th epoch across all runs: 0.6786\n",
      "Std. F1 score for the 8th epoch across all runs: 0.0299\n",
      "Mean AUROC VAL score for the 8th epoch across all runs: 0.7318\n",
      "Std. AUROC VAL score for the 8th epoch across all runs: 0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "get_val_metrics(runs=runs1, index=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 score for the 6th epoch across all runs: 0.6765\n",
      "Std. F1 score for the 6th epoch across all runs: 0.0303\n",
      "Mean AUROC VAL score for the 6th epoch across all runs: 0.7307\n",
      "Std. AUROC VAL score for the 6th epoch across all runs: 0.0346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "get_f1_mean_val(runs=runs1, index=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESNET50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 score for the 8th epoch across all runs: 0.6691\n",
      "Std. F1 score for the 8th epoch across all runs: 0.0415\n",
      "Mean AUROC VAL score for the 8th epoch across all runs: 0.7426\n",
      "Std. AUROC VAL score for the 8th epoch across all runs: 0.0260\n"
     ]
    }
   ],
   "source": [
    "get_f1_mean_val(runs=runs2, index=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 score for the 6th epoch across all runs: 0.6752\n",
      "Std. F1 score for the 6th epoch across all runs: 0.0224\n",
      "Mean AUROC VAL score for the 6th epoch across all runs: 0.7388\n",
      "Std. AUROC VAL score for the 6th epoch across all runs: 0.0257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "get_f1_mean_val(runs=runs2, index=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomedai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
